{
     "parent1": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted combination of edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the weighted combination of maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    weighted_combination = (0.4 * edge_n_used) + (0.6 * (local_opt_tour - global_opt_tour))\n    \n    new_distance_matrix = distance_matrix + weighted_combination\n    \n    perturb_nodes = np.argsort((0.6 * np.max(edge_n_used, axis=1)) + (0.4 * np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06466,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "Create a new algorithm that updates the distance matrix by considering the weighted sum of normalized edge usage, the difference between the local and global optimum tours, and randomness, and sorts the nodes based on the combination of edge usage and distance from the global optimum tour.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = distance_matrix + combined_metric + (0.1 * randomness)\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.05739,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted combination of edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the weighted combination of maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    weighted_combination = (0.4 * edge_n_used) + (0.6 * (local_opt_tour - global_opt_tour))\n    \n    new_distance_matrix = distance_matrix + weighted_combination\n    \n    perturb_nodes = np.argsort((0.6 * np.max(edge_n_used, axis=1)) + (0.4 * np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06466,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "Create an algorithm that updates the distance matrix by combining the distance from the global optimum tour and the edge usage, and then sorts the nodes based on the maximum edge usage and the minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    unique_score = global_opt_tour - local_opt_tour\n    new_distance_matrix = distance_matrix + (0.5 * edge_n_used) + unique_score\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06267,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "Create a new algorithm that updates the distance matrix by combining the weighted average of edge usage, the difference between local and global optimum tours, and randomness, and then sorts the nodes based on the maximum edge usage and the minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by combining the weighted average of edge usage, the difference between local and global optimum tours, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.4 * edge_n_used) + (0.4 * (local_opt_tour - global_opt_tour)) + (0.2 * randomness) + distance_matrix\n    \n    # Sort the nodes based on the maximum edge usage and the minimum distance from the global optimum tour\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06425,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "Common backbone idea: The algorithms all update the distance matrix by combining edge usage and the difference between local and global optimum tours, and then sort the nodes based on edge usage and distance from the global optimum tour.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update distance matrix by considering a weighted sum of edge usage and the difference between the local and global optimum tours, and sort nodes based on edge usage and distance from the global optimum tour\n    weighted_metric = (0.3 * edge_n_used) + (0.7 * (global_opt_tour - local_opt_tour))\n    new_distance_matrix = distance_matrix + weighted_metric\n    perturb_nodes = np.argsort((0.7 * np.max(edge_n_used, axis=1)) + (0.3 * np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.08767,
          "other_inf": null
     }
}