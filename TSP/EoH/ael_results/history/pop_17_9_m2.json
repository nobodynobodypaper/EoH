{
     "parent1": {
          "algorithm": "\nThe new algorithm will update the distance matrix by incorporating the absolute difference between the local and global optimum tours, a scaled sum of edge usage, randomness, and limited search space, and will sort the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation. \n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    difference_tour = np.abs(local_opt_tour - global_opt_tour)\n    scaled_edge_usage = edge_n_used / np.max(edge_n_used)\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    limited_search_space = (1 / (1 + np.exp(-distance_matrix)))  # Applying sigmoid function to limit the search space\n    new_distance_matrix = (0.2 * difference_tour) + (0.5 * scaled_edge_usage) + (0.1 * randomness) + (0.2 * limited_search_space)\n    weighted_distance = 0.4 * np.min(new_distance_matrix, axis=1) + 0.6 * np.max(scaled_edge_usage, axis=1)\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.21406,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "\nThe new algorithm will update the distance matrix by incorporating the absolute difference between the local and global optimum tours, a scaled sum of edge usage, randomness, and limited search space, and will sort the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation, using different parameter settings for the score function.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    difference_tour = np.abs(local_opt_tour - global_opt_tour)\n    scaled_edge_usage = edge_n_used / np.max(edge_n_used)\n    \n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])**2  # Increased emphasis on randomness\n    limited_search_space = 1 / (1 + np.exp(-distance_matrix * 1.5))  # Increased impact of sigmoid function\n    \n    new_distance_matrix = (0.3 * difference_tour) + (0.4 * scaled_edge_usage) + (0.2 * randomness) + (0.1 * limited_search_space)  # Adjusted weights\n    \n    weighted_distance = 0.3 * np.min(new_distance_matrix, axis=1) + 0.7 * np.max(scaled_edge_usage, axis=1)  # Changed weights for sorting\n    \n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.22822,
          "other_inf": null
     }
}