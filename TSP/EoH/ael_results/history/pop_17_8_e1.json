{
     "parent1": {
          "algorithm": "Create a new algorithm that updates the distance matrix by normalizing the edge usage and combining it with the average difference between local and global optimum tours, and sorts the nodes based on the minimum distance from the global optimum tour and maximum normalized edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.min(new_distance_matrix, axis=1), np.max(edge_n_used, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06714,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted combination of edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the weighted combination of maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    weighted_combination = (0.4 * edge_n_used) + (0.6 * (local_opt_tour - global_opt_tour))\n    \n    new_distance_matrix = distance_matrix + weighted_combination\n    \n    perturb_nodes = np.argsort((0.6 * np.max(edge_n_used, axis=1)) + (0.4 * np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06466,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "\nCreate an algorithm that updates the distance matrix by incorporating a weighted sum of the difference between the local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.3 * (global_opt_tour - local_opt_tour)) + (0.6 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    weighted_distance = 0.4 * np.min(new_distance_matrix, axis=1) + 0.6 * np.max(edge_n_used, axis=1)\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    perturb_nodes = np.array(perturb_nodes) # simplify the perturb_nodes to ensure consistency in type\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06548,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "\nCreate a new algorithm that updates the distance matrix by incorporating the combination of edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef simplify_components(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    unique_score = (local_opt_tour - global_opt_tour)\n    \n    new_distance_matrix = distance_matrix + (0.5 * edge_n_used) + unique_score\n    \n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06562,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "\nCreate a new algorithm that updates the distance matrix by incorporating the combination of edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef simplify_components(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    unique_score = (local_opt_tour - global_opt_tour)\n    \n    new_distance_matrix = distance_matrix + (0.5 * edge_n_used) + unique_score\n    \n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06562,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "Create a new algorithm that updates the distance matrix by incorporating a combination of the normalized edge usage, the average difference between local and global optimum tours, and the randomness, and sorts the nodes based on the maximum normalized edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = distance_matrix + combined_metric + (0.1 * randomness)\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.03538,
          "other_inf": null
     }
}