{
     "parent1": {
          "algorithm": "\nThe new algorithm will identify the edges that are commonly used in the local optimal tour and calculate the total distance reduction if each node is perturbed. Then, it will update the distance matrix by adjusting the distances of the edges based on their frequency of use and the potential impact of perturbing each node. Finally, it will sort the nodes based on the penalty and perturb impact to avoid being trapped in the local optimum tour and return the updated distance matrix and the sorted nodes to perturb, prioritizing nodes that will lead to minimized total distance.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    penalty = np.zeros(distance_matrix.shape)\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        penalty[start][end] += 1\n        penalty[end][start] += 1\n    penalty = np.divide(penalty, (edge_n_used + 1), out=np.zeros_like(penalty), where=(edge_n_used + 1) != 0)\n    new_distance_matrix = distance_matrix + penalty * (edge_n_used + 1)\n    perturb_impact = np.sum((1 / (edge_n_used + 1)) * (distance_matrix - new_distance_matrix), axis=1)\n    perturb_nodes = np.argsort(-penalty.sum(axis=1) + perturb_impact)\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.304,
          "first_obj": null
     },
     "parent2": {
          "algorithm": "\nThe algorithm will first identify the edges that are commonly used in the local optimal tour and calculate the total distance reduction if each node is perturbed. Then, it will update the distance matrix by penalizing the edges based on their frequency of use and the potential impact of perturbing each node, and finally sort the nodes based on the penalty and perturb impact to avoid being trapped in the local optimum tour.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    penalty = np.zeros(distance_matrix.shape)\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        penalty[start][end] += 1\n        penalty[end][start] += 1\n    penalty = np.divide(penalty, edge_n_used, out=np.zeros_like(penalty), where=edge_n_used != 0)\n    new_distance_matrix = distance_matrix + penalty * edge_n_used\n    perturb_impact = np.sum(edge_n_used * (distance_matrix - new_distance_matrix), axis=1)\n    perturb_nodes = np.argsort(-penalty.sum(axis=1) + perturb_impact)[::-1]\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.333,
          "first_obj": null
     },
     "offspring": {
          "algorithm": "\nThe new algorithm will first identify the edges that are frequently used in the local optimal tour and calculate the total distance reduction if each node is perturbed. Then, it will update the distance matrix by adjusting the distances of the edges based on their frequency of use and the potential impact of perturbing each node. Finally, it will use a clustering algorithm to group the nodes in the distance matrix based on their proximity and sort the nodes within each cluster based on the perturb impact to avoid being trapped in the local optimum tour, prioritizing nodes that will lead to minimized total distance.\n",
          "code": "import numpy as np\nfrom scipy.cluster.vq import kmeans2\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    penalty = np.zeros(distance_matrix.shape)\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        penalty[start][end] += 1\n        penalty[end][start] += 1\n    penalty = np.divide(penalty, (edge_n_used + 1), out=np.zeros_like(penalty), where=(edge_n_used + 1) != 0)\n    new_distance_matrix = distance_matrix + penalty * (edge_n_used + 1)\n    perturb_impact = np.sum((1 / (edge_n_used + 1)) * (distance_matrix - new_distance_matrix), axis=1)\n    \n    # Clustering nodes\n    centroids, _ = kmeans2(distance_matrix, k=3, iter=20)  # Assuming 3 clusters for illustration\n    clusters = [[] for _ in range(3)]\n    for ind, node in enumerate(distance_matrix):\n        predicted_label = np.argmin(np.linalg.norm(node - centroids, axis=1))\n        clusters[predicted_label].append(ind)\n    \n    sorted_perturb_nodes = []\n    for cluster in clusters:\n        cluster_perturb_impact = perturb_impact[cluster]\n        cluster_perturb_nodes = np.argsort(-cluster_perturb_impact)\n        sorted_perturb_nodes.extend(cluster[cluster_perturb_nodes])\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 10000000000.0,
          "first_obj": null
     }
}