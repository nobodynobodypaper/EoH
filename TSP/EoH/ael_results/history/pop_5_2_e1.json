{
     "parent1": {
          "algorithm": "New algorithm: Update the edge distances in the edge distance matrix based on the frequency of each edge used in the local optimal tour using a noise factor that depends on a custom combination of edge count and distance to guide the search towards a better solution.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = np.random.uniform(-0.5, 0.5) * edge_count[i][j] + (1 / max(edge_n_used[i][j], 1)) * (edge_distance[i][j] / np.max(edge_distance))\n                updated_edge_distance[i][j] += noise_factor\n\n    return updated_edge_distance",
          "objective": 0.02634,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix by considering the edge count, edge distance, and the reciprocal of edge usage, and using a unique heuristic that involves scaling the edge count and distance based on their relative magnitude, and then combining them with the reciprocal of edge usage to update the edge distances.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_n_used)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                scale_factor = 10 / (edge_count[i][j] * edge_distance[i][j])  # Unique scaling factor\n                updated_edge_distance[i][j] += scale_factor * (edge_count[i][j] + edge_distance[i][j]) * (1 / max(edge_n_used[i][j], 1))\n\n    return updated_edge_distance",
          "objective": 0.07724,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "New algorithm: Update the edge distances in the edge distance matrix based on the frequency of each edge used in the local optimal tour using a noise factor that depends on the edge count and the edge distance to guide the search towards a better solution with a bias towards lesser used edges and longer distances.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = np.random.uniform(-1 / edge_count[i][j], 1 / edge_count[i][j]) + (edge_distance[i][j] / np.max(edge_distance))\n                updated_edge_distance[i][j] += noise_factor\n\n    return updated_edge_distance",
          "objective": 0.0905,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix based on the frequency of each edge used in the local optimal tour using a noise factor that depends on the edge count and the edge distance to guide the search towards a better solution with a bias towards lesser used edges and longer distances, but incorporating a decay factor to reduce the impact of noise on heavily used edges.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = np.random.uniform(-1 / edge_count[i][j], 1 / edge_count[i][j]) + (edge_distance[i][j] / np.max(edge_distance))\n                noise_factor *= np.exp(-0.1 * edge_n_used[i][j])  # Applying decay factor\n                updated_edge_distance[i][j] += noise_factor\n\n    return updated_edge_distance",
          "objective": 0.08494,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix by considering the weighted combination of edge count, edge distance, and the reciprocal of edge usage, using a predefined weighting factor to guide the search towards a better solution with a balanced bias towards different factors.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_n_used)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    weight_factor = 0.4  # Predefined weighting factor\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                updated_edge_distance[i][j] += weight_factor * (edge_count[i][j] + (1 / max(edge_n_used[i][j], 1))) + (1 - weight_factor) * (edge_distance[i][j] / np.max(edge_distance))\n\n    return updated_edge_distance",
          "objective": 0.07213,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix based on the combination of edge count, edge distance, and edge usage, using a dynamic heuristic that adjusts the update based on the distribution of edge count and distance in the matrix to guide the search towards a diverse set of potential optimal solutions.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n    edge_distance_flat = edge_distance.flatten()\n    edge_count_flat = edge_count.flatten()\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    edge_count_mean = np.mean(edge_count_flat)\n    edge_count_std = np.std(edge_count_flat)\n    edge_distance_mean = np.mean(edge_distance_flat)\n    edge_distance_std = np.std(edge_distance_flat)\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                count_diff = (edge_count[i][j] - edge_count_mean) / edge_count_std\n                distance_diff = (edge_distance[i][j] - edge_distance_mean) / edge_distance_std\n                updated_edge_distance[i][j] += count_diff + distance_diff\n\n    return updated_edge_distance",
          "objective": 2.89268,
          "other_inf": null
     }
}