{
     "parent1": {
          "algorithm": "Create a new algorithm that updates the distance matrix by normalizing the edge usage and combining it with the average difference between local and global optimum tours, and sorts the nodes based on the minimum distance from the global optimum tour and maximum normalized edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.min(new_distance_matrix, axis=1), np.max(edge_n_used, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06714,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "Create a new algorithm that updates the distance matrix by normalizing the edge usage and combining it with the average difference between local and global optimum tours, and sorts the nodes based on the minimum distance from the global optimum tour and maximum normalized edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.min(new_distance_matrix, axis=1), np.max(edge_n_used, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06714,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "\nCreate an algorithm that updates the distance matrix by incorporating a weighted sum of the difference between the local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by incorporating a weighted sum of the difference between the local and global optimum tours, edge usage, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.3 * (global_opt_tour - local_opt_tour)) + (0.6 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    # Sort the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage\n    weighted_distance = 0.4 * np.min(new_distance_matrix, axis=1) + 0.6 * np.max(edge_n_used, axis=1)\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06412,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "\nCreate an algorithm that updates the distance matrix by incorporating a weighted sum of the difference between the local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by incorporating a weighted sum of the difference between the local and global optimum tours, edge usage, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.3 * (global_opt_tour - local_opt_tour)) + (0.6 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    # Sort the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage\n    weighted_distance = 0.4 * np.min(new_distance_matrix, axis=1) + 0.6 * np.max(edge_n_used, axis=1)\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06412,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "Create a new algorithm that updates the distance matrix by combining the weighted average of edge usage, the difference between local and global optimum tours, and randomness, and then sorts the nodes based on the maximum edge usage and the minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by combining the weighted average of edge usage, the difference between local and global optimum tours, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.4 * edge_n_used) + (0.4 * (local_opt_tour - global_opt_tour)) + (0.2 * randomness) + distance_matrix\n    \n    # Sort the nodes based on the maximum edge usage and the minimum distance from the global optimum tour\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06425,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "Create a new algorithm that uses a genetic algorithm approach to update the distance matrix, taking into account crossover and mutation operations, and sorts the nodes based on a fitness function incorporating edge usage, local and global optimum tours to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    population_size = 100\n    generations = 50\n\n    # Create initial population with random solutions\n    population = np.random.randint(0, 2, size=(population_size, distance_matrix.shape[0]))\n\n    for generation in range(generations):\n        # Calculate fitness for each solution in the population\n        fitness = np.zeros(population_size)\n        for i in range(population_size):\n            fitness[i] = 0.4 * np.min(distance_matrix @ population[i]) + 0.6 * np.max(edge_n_used @ population[i])\n\n        # Select the top solutions for reproduction\n        selected_indices = np.argsort(fitness)[:10]\n        selected_population = population[selected_indices]\n\n        # Perform crossover and mutation operations\n        new_population = np.zeros((population_size, distance_matrix.shape[0]))\n        for i in range(population_size):\n            parent1 = selected_population[np.random.randint(10)]\n            parent2 = selected_population[np.random.randint(10)]\n            crossover_point = np.random.randint(distance_matrix.shape[0])\n            new_population[i] = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n\n            mutation_rate = 0.1\n            if np.random.rand() < mutation_rate:\n                mutation_point = np.random.randint(distance_matrix.shape[0])\n                new_population[i, mutation_point] = 1 - new_population[i, mutation_point]\n\n        population = new_population\n\n    # Select the best solution as the updated distance matrix\n    best_solution = selected_population[0]\n    new_distance_matrix = distance_matrix.copy()\n    for i in range(distance_matrix.shape[0]):\n        for j in range(distance_matrix.shape[0]):\n            if best_solution[i] != best_solution[j]:\n                new_distance_matrix[i, j] *= 1.1\n\n    # Sort the nodes based on the best solution\n    perturb_nodes = np.argsort(best_solution)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 10000000000.0,
          "other_inf": null
     }
}