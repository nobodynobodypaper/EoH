{
     "parent1": {
          "algorithm": "Create a new algorithm that updates the distance matrix by combining the exponential of the normalized edge usage, the absolute difference between the local and global optimum tours, and a random factor, and sorts the nodes based on the maximum distance from the global optimum tour and minimum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.8 * np.exp(edge_n_used / np.max(edge_n_used))) + (0.2 * np.abs(local_opt_tour - global_opt_tour)) + (0.1 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.minimum(np.min(edge_n_used, axis=1), np.max(new_distance_matrix, axis=1)))\n\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.50784,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "Create a new algorithm that updates the distance matrix by combining the exponential of the normalized edge usage, the absolute difference between the local and global optimum tours, and a random factor, and sorts the nodes based on the maximum distance from the global optimum tour and minimum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, edge_n_used):\n    combined_metric = (0.8 * np.exp(edge_n_used / np.max(edge_n_used))) + (0.1 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.minimum(np.min(edge_n_used, axis=1), np.max(new_distance_matrix, axis=1)))\n\n    return new_distance_matrix, perturb_nodes",
          "objective": 10000000000.0,
          "other_inf": null
     }
}