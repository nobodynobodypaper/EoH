{
     "parent1": {
          "algorithm": "The common backbone idea in the provided algorithms is to update the distance matrix by incorporating the difference between local and global optimum tours, edge usage, and randomness, and then sorting the nodes based on certain criteria.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    normalized_edge_usage = edge_n_used / np.max(edge_n_used)\n    weighted_tour_difference = 0.6 * (local_opt_tour - global_opt_tour)\n    additional_randomness = 0.4 * np.random.rand(*distance_matrix.shape)\n    \n    new_distance_matrix = distance_matrix + normalized_edge_usage + weighted_tour_difference + additional_randomness\n    perturb_nodes = np.argsort(np.maximum(np.max(normalized_edge_usage, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.09576,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "The new algorithm incorporates a different parameter settings in the score function by using a combination of edge usage, local and global optimal tour differences, and a modified randomness factor to update the distance matrix and sort the nodes based on specific criteria.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    normalized_edge_usage = edge_n_used / np.max(edge_n_used)\n    weighted_tour_difference = 0.8 * (local_opt_tour - global_opt_tour)\n    additional_randomness = 0.2 * np.random.rand(*distance_matrix.shape)\n    \n    new_distance_matrix = distance_matrix + normalized_edge_usage + weighted_tour_difference + additional_randomness\n    perturb_nodes = np.argsort(np.maximum(np.max(normalized_edge_usage, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.09698,
          "other_inf": null
     }
}