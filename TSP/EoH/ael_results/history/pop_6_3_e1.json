{
     "parent1": {
          "algorithm": "New algorithm: Update the edge distances in the edge distance matrix based on the frequency of each edge used in the local optimal tour using a noise factor that depends on a custom combination of edge count and distance to guide the search towards a better solution.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = np.random.uniform(-0.5, 0.5) * edge_count[i][j] + (1 / max(edge_n_used[i][j], 1)) * (edge_distance[i][j] / np.max(edge_distance))\n                updated_edge_distance[i][j] += noise_factor\n\n    return updated_edge_distance",
          "objective": 0.02634,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix based on the occurrence of each edge used in the local optimal tour with a noise factor that depends on a custom combination of edge count, distance, and edge usage to guide the search towards a better solution using a modified scoring function with a lower noise factor, a higher weight for edge count, and a penalty for overused edges.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    \n    edge_count = np.zeros_like(edge_distance)\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n    \n    mean_edge_distance = np.mean(edge_distance)\n    max_edge_usage = np.max(edge_n_used)\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = 0.5 * np.random.uniform() * (1 / edge_count[i][j]) + (edge_distance[i][j] / mean_edge_distance) - 0.2 * (edge_n_used[i][j] / max_edge_usage)\n                updated_edge_distance[i][j] += noise_factor * (1 + edge_count[i][j])\n\n    return updated_edge_distance",
          "objective": 0.02789,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "New algorithm: Update the edge distances in the edge distance matrix by considering the weighted combination of edge count, edge distance, and the reciprocal of edge usage, using a different predefined weighting factor to guide the search towards a better solution with a balanced bias towards different factors.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_n_used)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    weight_factor = 0.8  # Adjusted weight factor\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                updated_edge_distance[i][j] += weight_factor * (edge_count[i][j] + (1 / max(edge_n_used[i][j], 1))) + (1 - weight_factor) * (edge_distance[i][j] / np.max(edge_distance))\n\n    return updated_edge_distance",
          "objective": 0.04025,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "New algorithm: Update the edge distances in the edge distance matrix by considering the weighted combination of edge count, edge distance, and the reciprocal of edge usage, using a different predefined weighting factor to guide the search towards a better solution with a balanced bias towards different factors.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_n_used)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    weight_factor = 0.8  # Adjusted weight factor\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                updated_edge_distance[i][j] += weight_factor * (edge_count[i][j] + (1 / max(edge_n_used[i][j], 1))) + (1 - weight_factor) * (edge_distance[i][j] / np.max(edge_distance))\n\n    return updated_edge_distance",
          "objective": 0.04025,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix based on the minimum frequency of each edge used in the local optimal tour and a custom transformation of the edge count and distance, incorporating a noise factor proportional to the reciprocal of the edge count and a scaled factor based on the distance to guide the search towards a better solution.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    edge_count = np.zeros_like(edge_distance)\n\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = (1 / max(edge_count[i][j], 1)) * (edge_distance[i][j] / np.max(edge_distance))\n                scaled_factor = 0.7 * np.random.uniform(0.5, 1.5) * (1 / edge_count[i][j]) + 0.3 * (edge_distance[i][j] / np.mean(edge_distance))\n                updated_edge_distance[i][j] += scaled_factor + noise_factor\n\n    return updated_edge_distance",
          "objective": 0.0467,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "\nNew algorithm: Update the edge distances in the edge distance matrix by considering the combination of edge count, distance, and usage, with a focus on promoting exploration by applying a dynamic noise factor and leveraging a custom heuristics function to guide the search towards a better solution.\n",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    updated_edge_distance = np.copy(edge_distance)\n    \n    edge_count = np.zeros_like(edge_distance)\n    for i in range(len(local_opt_tour) - 1):\n        start = local_opt_tour[i]\n        end = local_opt_tour[i + 1]\n        edge_count[start][end] += 1\n        edge_count[end][start] += 1\n    \n    max_edge_usage = np.max(edge_n_used)\n    mean_edge_distance = np.mean(edge_distance)\n\n    for i in range(edge_distance.shape[0]):\n        for j in range(edge_distance.shape[1]):\n            if edge_count[i][j] > 0:\n                noise_factor = (np.random.uniform(0.7, 1.3) / edge_count[i][j]) + (edge_distance[i][j] / mean_edge_distance) - (0.3 / max_edge_usage) * edge_n_used[i][j]\n                updated_edge_distance[i][j] += noise_factor * (1 + edge_count[i][j])\n\n    return updated_edge_distance",
          "objective": 0.03322,
          "other_inf": null
     }
}