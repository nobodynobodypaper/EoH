{
     "parent1": {
          "algorithm": "\nThe new algorithm computes a combination of the normalized edge usage, the weighted average of the difference between local and global optimum tours, and additional randomness, updates the distance matrix, and then sorts the nodes based on the maximum normalized edge usage and minimum distance from the global optimum tour to determine the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.3 * (edge_n_used / np.max(edge_n_used))) + (0.6 * (local_opt_tour - global_opt_tour)) + (0.1 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.0607,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "\nThe new algorithm computes a combination of the normalized edge usage, the weighted average of the difference between local and global optimum tours, and additional randomness, updates the distance matrix, and then sorts the nodes based on the maximum normalized edge usage and minimum distance from the global optimum tour to determine the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, edge_n_used):\n    combined_metric = (0.3 * (edge_n_used / np.max(edge_n_used))) + (0.6 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.max(edge_n_used, axis=1) if np.max(edge_n_used) > np.min(new_distance_matrix) else np.min(new_distance_matrix, axis=1))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 10000000000.0,
          "other_inf": null
     }
}