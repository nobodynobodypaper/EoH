{
     "parent1": {
          "algorithm": "Create a new algorithm that updates the distance matrix by incorporating a combination of the difference between the local and global optimum tours, the inverse of the edge usage, and a random factor, then sorts the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    tour_difference = (local_opt_tour - global_opt_tour)\n    inverse_edge_usage = 1 / edge_n_used\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    \n    new_distance_matrix = distance_matrix + tour_difference + inverse_edge_usage + (0.1 * randomness)\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 3.49348,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "Create a new algorithm that updates the distance matrix by incorporating a combination of the difference between the local and global optimum tours, the inverse of the edge usage, and a random factor, then sorts the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    tour_difference = (local_opt_tour - global_opt_tour)\n    inverse_edge_usage = 1 / edge_n_used\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    \n    new_distance_matrix = distance_matrix + tour_difference + inverse_edge_usage + (0.1 * randomness)\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 3.49348,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "Create a new algorithm that updates the distance matrix by combining the exponential of the difference between the local and global optimum tours, the product of the edge usage and a random factor, and then sorts the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    tour_difference_exp = np.exp(local_opt_tour - global_opt_tour)\n    product_avg_random = np.mean(edge_n_used, axis=1) * np.random.rand(distance_matrix.shape[0])\n    \n    new_distance_matrix = distance_matrix + tour_difference_exp + product_avg_random\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.04932,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "Create a new algorithm that updates the distance matrix by incorporating a combination of the difference between the local and global optimum tours, the inverse of the edge usage, and a random factor, then sorts the nodes based on the minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    tour_difference = (local_opt_tour - global_opt_tour)\n    inverse_edge_usage = 1 / edge_n_used\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    \n    new_distance_matrix = distance_matrix + tour_difference + inverse_edge_usage + (0.1 * randomness)\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 3.49348,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "\nCreate a novel algorithm that updates the distance matrix by computing a combination of the normalized edge usage, the weighted average of the difference between local and global optimum tours, and additional randomness, then sorts the nodes based on the maximum normalized edge usage and minimum distance from the global optimum tour to determine the top nodes for perturbation.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.5 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour)) + (0.1 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(new_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.05104,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "Create a new algorithm that incorporates a weighted combination of the difference between the local and global optimum tours, the maximum edge usage, and a unique normalization factor, then sorts the nodes based on the maximum edge usage and minimum distance from the global optimum tour to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    weighted_combination = (0.3 * (local_opt_tour - global_opt_tour)) + (0.5 * edge_n_used / np.max(edge_n_used)) + (0.2 * np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1]))\n    normalization_factor = np.sum(weighted_combination, axis=1, keepdims=True)\n    normalized_distance_matrix = distance_matrix + weighted_combination / normalization_factor\n    perturb_nodes = np.argsort(np.maximum(np.max(edge_n_used, axis=1), np.min(normalized_distance_matrix, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 10000000000.0,
          "other_inf": null
     }
}