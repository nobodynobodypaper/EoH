{
     "parent1": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.6 * (local_opt_tour - global_opt_tour)) + (0.3 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    # Sort the nodes based on a combination of maximum distance from the global optimum tour and minimum edge usage\n    min_distance = np.min(new_distance_matrix, axis=1)\n    max_edge_usage = np.max(edge_n_used, axis=1)\n    weighted_distance = 0.4 * min_distance + 0.6 * max_edge_usage\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06676,
          "other_inf": null
     },
     "parent2": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.6 * (local_opt_tour - global_opt_tour)) + (0.3 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    # Sort the nodes based on a combination of maximum distance from the global optimum tour and minimum edge usage\n    min_distance = np.min(new_distance_matrix, axis=1)\n    max_edge_usage = np.max(edge_n_used, axis=1)\n    weighted_distance = 0.4 * min_distance + 0.6 * max_edge_usage\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06676,
          "other_inf": null
     },
     "parent3": {
          "algorithm": "Create an algorithm that updates the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness, and sorts the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Update the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness\n    randomness = np.random.rand(distance_matrix.shape[0], distance_matrix.shape[1])\n    new_distance_matrix = (0.6 * (local_opt_tour - global_opt_tour)) + (0.3 * edge_n_used) + (0.1 * randomness) + distance_matrix\n    \n    # Sort the nodes based on a combination of maximum distance from the global optimum tour and minimum edge usage\n    min_distance = np.min(new_distance_matrix, axis=1)\n    max_edge_usage = np.max(edge_n_used, axis=1)\n    weighted_distance = 0.4 * min_distance + 0.6 * max_edge_usage\n    perturb_nodes = np.argsort(weighted_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06676,
          "other_inf": null
     },
     "parent4": {
          "algorithm": "Create a new algorithm that updates the distance matrix by normalizing the edge usage and combining it with the average difference between local and global optimum tours, and sorts the nodes based on the minimum distance from the global optimum tour and maximum normalized edge usage to identify the top nodes for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    combined_metric = (0.6 * (edge_n_used / np.max(edge_n_used))) + (0.4 * (local_opt_tour - global_opt_tour))\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.maximum(np.min(new_distance_matrix, axis=1), np.max(edge_n_used, axis=1)))\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06714,
          "other_inf": null
     },
     "parent5": {
          "algorithm": "\nNew algorithm: Calculate the updated distance matrix by combining edge usage and the difference between local and global optimum tours, and then sort the nodes based on a different formula to identify top nodes for perturbation, with the final goal of finding a tour with minimized total distance.\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    edge_usage_score = 0.5 * edge_n_used\n    unique_score = local_opt_tour - global_opt_tour\n    initial_distance_score = distance_matrix\n\n    new_distance_matrix = initial_distance_score + edge_usage_score + unique_score\n    \n    max_edge_usage = np.max(edge_n_used, axis=1)\n    min_global_distance = np.min(new_distance_matrix, axis=1)\n    perturb_nodes = np.argsort(max_edge_usage + min_global_distance)\n    \n    return new_distance_matrix, perturb_nodes",
          "objective": 0.06267,
          "other_inf": null
     },
     "offspring": {
          "algorithm": "\nThe common backbone idea in the provided algorithms is to update the distance matrix by incorporating a weighted average of the difference between local and global optimum tours, edge usage, and randomness, and sort the nodes based on a combination of minimum distance from the global optimum tour and maximum edge usage to identify the top nodes for perturbation.\n}\n\n```python\nimport numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Create a new algorithm that updates the distance matrix by combining the normalized edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the sum of the normalized edge usage and the minimum distance from the global optimum tour to identify the top nodes for perturbation\n    normalized_edge_usage = edge_n_used / np.max(edge_n_used)\n    combined_metric = normalized_edge_usage + (local_opt_tour - global_opt_tour)\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.sum(combined_metric, axis=1))\n\n    return new_distance_matrix, perturb_nodes\n",
          "code": "import numpy as np\n\ndef get_matrix_and_nodes(distance_matrix, local_opt_tour, global_opt_tour, edge_n_used):\n    # Create a new algorithm that updates the distance matrix by combining the normalized edge usage and the difference between local and global optimum tours, and then sorts the nodes based on the sum of the normalized edge usage and the minimum distance from the global optimum tour to identify the top nodes for perturbation\n    normalized_edge_usage = edge_n_used / np.max(edge_n_used)\n    combined_metric = normalized_edge_usage + (local_opt_tour - global_opt_tour)\n    new_distance_matrix = distance_matrix + combined_metric\n    perturb_nodes = np.argsort(np.sum(combined_metric, axis=1))\n\n    return new_distance_matrix, perturb_nodes",
          "objective": 0.07311,
          "other_inf": null
     }
}